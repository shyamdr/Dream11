{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37e6af0b",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0443170",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-14T19:41:54.764479Z",
     "start_time": "2023-09-14T19:41:54.756969Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import espncricinfo as ci\n",
    "import ipywidgets as widgets\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bf4a85",
   "metadata": {},
   "source": [
    "# Setting configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6fe500",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-14T19:41:55.483059Z",
     "start_time": "2023-09-14T19:41:55.468627Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "comm_filepath = os.path.abspath(os.path.join(os.getcwd(), \"../../../data/CommExtract/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae02b101",
   "metadata": {},
   "source": [
    "# Initializing paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4e7f9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-14T19:42:14.816837Z",
     "start_time": "2023-09-14T19:42:14.810326Z"
    }
   },
   "outputs": [],
   "source": [
    "year = '2023'\n",
    "series = 'indian-premier-league-2023'\n",
    "matchid = '66173'\n",
    "scroll_pause_time = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa75d02",
   "metadata": {},
   "source": [
    "# Web Scrapping - Cricbuzz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf5bb96",
   "metadata": {},
   "source": [
    "### Finding all the series from the yearly calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee3000d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-14T19:42:17.068935Z",
     "start_time": "2023-09-14T19:42:16.799768Z"
    }
   },
   "outputs": [],
   "source": [
    "base_url = 'https://www.cricbuzz.com/cricket-scorecard-archives/'\n",
    "url = base_url + year\n",
    "\n",
    "\n",
    "page = requests.get(url)\n",
    "bs = BeautifulSoup(page.content, 'lxml')\n",
    "\n",
    "links = bs.find_all('a', href=lambda href: href and 'matches' in href)\n",
    "\n",
    "series_list = []\n",
    "for link in links:\n",
    "    href = link['href']\n",
    "    columns = href.split('/')[2:4]\n",
    "    #columns[-1] = columns[-1].replace('-', ' ') ---> for better readability convert code to proper text\n",
    "    series_list.append(columns)\n",
    "\n",
    "series_id = next((row[0] for row in series_list if row[1] == series), None)\n",
    "\n",
    "print(str(len(series_list)) + ' series found in the year ' + year)\n",
    "print('Current series selected is :- ' + series)\n",
    "print('Series ID : ' + series_id)\n",
    "#series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433d3a0d",
   "metadata": {},
   "source": [
    "### Finding all the matches from the given series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec81d51d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-14T19:42:18.657989Z",
     "start_time": "2023-09-14T19:42:18.516631Z"
    }
   },
   "outputs": [],
   "source": [
    "base_url = 'https://www.cricbuzz.com/cricket-series/'\n",
    "url = base_url + series_id + '/' + series + '/matches'\n",
    "\n",
    "page = requests.get(url)\n",
    "bs = BeautifulSoup(page.content, 'lxml')\n",
    "\n",
    "links = bs.select('div.page')[0].find_all('a', href=lambda href: href and (\n",
    "    '/cricket-scores/' in href or (series in href and '/live-cricket-scores/' in href)))\n",
    "\n",
    "matches = []\n",
    "for link in links:\n",
    "    href = link['href']\n",
    "    column = href.split('/')[2:4]\n",
    "    matches.append(column)\n",
    "    \n",
    "matches = list(set(map(tuple,matches)))\n",
    "matches.sort(key=lambda x: int(x[0]))\n",
    "\n",
    "# match_id = next((row[0] for row in matches if row[1] == match_wg.value), None)\n",
    "# match_id = MATCHID\n",
    "match = next((row[1] for row in matches if row[0] == matchid), None)\n",
    "\n",
    "print(str(len(matches)) + ' matches found in the series - ' + series.replace('-', ' ') + ' for the year ' + year)\n",
    "print('Current match selected is :- ' + match)\n",
    "print('Match ID : ' + matchid)\n",
    "\n",
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bfd67c",
   "metadata": {},
   "source": [
    "### Get full commentary using a dynamic scroll with a timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767d9c16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-14T19:43:19.109276Z",
     "start_time": "2023-09-14T19:42:28.942588Z"
    }
   },
   "outputs": [],
   "source": [
    "base_url = 'https://www.cricbuzz.com/cricket-scores/'\n",
    "url = base_url + matchid + '/' + match\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "\n",
    "driver = webdriver.Chrome(options=chrome_options)   # Set up the driver\n",
    "driver.get(url)\n",
    "\n",
    "wait = WebDriverWait(driver, 10)   # Set a wait time for explicit waits\n",
    "\n",
    "# Find the element by text\n",
    "element_text = \"Load More Commentary\"\n",
    "element_xpath = f\"//*[contains(text(), '{element_text}')]\"\n",
    "element = wait.until(EC.visibility_of_element_located((By.XPATH, element_xpath)))\n",
    "\n",
    "driver.execute_script(\"arguments[0].scrollIntoView();\", element)   # Scroll to the element\n",
    "\n",
    "driver.execute_script(\"arguments[0].click();\", element)   # Perform JavaScript click\n",
    "\n",
    "# Get scroll height\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "print(\"last_height - \" + str(last_height))\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "while True:\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")   # Scroll down to bottom\n",
    "    time.sleep(0.3)   # Wait to load page\n",
    "    #driver.implicitly_wait(0.3)\n",
    "    #element = wait.until(EC.presence_of_element_located((By.XPATH, element_xpath)))\n",
    "\n",
    "\n",
    "    # Calculate new scroll height and compare with last scroll height\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    print(\"new_height - \" + str(new_height))\n",
    "    \n",
    "    if new_height != last_height:\n",
    "        start_time = time.time()\n",
    "        print(\"New content found. Resetting start_time...\")\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    if elapsed_time > SCROLL_PAUSE_TIME:\n",
    "        print(\"No new content found. Breaking now...\")\n",
    "        break\n",
    "    \n",
    "    last_height = new_height\n",
    "\n",
    "# Get the updated page source\n",
    "updated_page_source = driver.page_source\n",
    "\n",
    "# Perform further actions on the updated page source if needed\n",
    "bs = BeautifulSoup(updated_page_source, 'lxml')\n",
    "#print(bs.body.prettify())\n",
    "\n",
    "driver.quit()   # Close the driver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1213bf45",
   "metadata": {},
   "source": [
    "# Extract clean text parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e56e0c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-14T19:48:25.594531Z",
     "start_time": "2023-09-14T19:48:25.527443Z"
    }
   },
   "outputs": [],
   "source": [
    "div_elements = bs.find_all('div', {'ng-include': \"'commentary'\"})\n",
    "\n",
    "text_parts = []\n",
    "for div in div_elements:\n",
    "    texts = div.find_all(text=True)\n",
    "    cleaned_texts = [text.strip() for text in texts if text.strip() and \n",
    "                     not text.strip().startswith('ngIf:') and \n",
    "                     not text.strip().startswith('end ngIf:') and \n",
    "                     not text.strip().startswith('ngRepeat:') and\n",
    "                     not text.strip().startswith('ngInclude:') and\n",
    "                     not text.strip().startswith('end ngRepeat')]\n",
    "    text_parts.extend(cleaned_texts)\n",
    "\n",
    "#print(text_parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153b963a",
   "metadata": {},
   "source": [
    "# Save the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf7d602",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-14T19:48:36.659986Z",
     "start_time": "2023-09-14T19:48:36.636403Z"
    }
   },
   "outputs": [],
   "source": [
    "path = comm_filepath + '\\\\comm_' + matchid + '.txt'\n",
    "\n",
    "# Delete the file if exists\n",
    "os.remove(path) if os.path.exists(path) else None\n",
    "\n",
    "# Save the list to a text file\n",
    "with open(path, 'w') as f:\n",
    "    for item in text_parts:\n",
    "        f.write(f\"{item}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
