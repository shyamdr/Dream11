{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b85b9ee8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a26ef43b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T10:15:42.023439Z",
     "start_time": "2024-01-01T10:15:42.005770Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import io\n",
    "import zipfile\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import modules.psql as psql\n",
    "from sqlalchemy import types as altypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1b8138",
   "metadata": {},
   "source": [
    "## Postgres Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1710c3bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T10:15:42.383041Z",
     "start_time": "2024-01-01T10:15:42.327973Z"
    }
   },
   "outputs": [],
   "source": [
    "%run config_psql.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3773860a",
   "metadata": {},
   "source": [
    "## Settings Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33156a11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T10:15:42.808541Z",
     "start_time": "2024-01-01T10:15:42.793909Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Settings configurations\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f847205",
   "metadata": {},
   "source": [
    "## Initializing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84a070f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T10:15:43.115395Z",
     "start_time": "2024-01-01T10:15:43.080757Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = \"https://cricsheet.org/downloads/recently_played_30_json.zip\"\n",
    "filetype = \".json\"\n",
    "\n",
    "df_meta = pd.DataFrame()\n",
    "df_match = pd.DataFrame()\n",
    "df_official = pd.DataFrame()\n",
    "df_registry = pd.DataFrame()\n",
    "df_player = pd.DataFrame()\n",
    "df_innings = pd.DataFrame()\n",
    "df_deliveries = pd.DataFrame()\n",
    "df_powerplay = pd.DataFrame()\n",
    "df_absent_hurt = pd.DataFrame()\n",
    "df_miscounted_overs = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8554acca",
   "metadata": {},
   "source": [
    "## Read the downloaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3f64acd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T10:15:48.193588Z",
     "start_time": "2024-01-01T10:15:43.495596Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    content = response.content\n",
    "    \n",
    "    zip_file = zipfile.ZipFile(io.BytesIO(content))\n",
    "    \n",
    "    with zip_file.open('README.txt') as f:\n",
    "        lines = [line.decode('utf-8') for line in f.readlines()]\n",
    "        pattern = re.compile(r'(\\d{4}-\\d{2}-\\d{2}) - ([^-]+) - ([^-]+) - (\\w+) - (\\d+) - (.+)')\n",
    "        ids = [match.group(5) for line in lines if (match := pattern.match(line))]\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1aa23f9",
   "metadata": {},
   "source": [
    "## Building indivudal DataFrames for different tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36ce7cd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T10:16:01.690856Z",
     "start_time": "2024-01-01T10:15:48.195606Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110  files present\n",
      "1386110 executed!\n",
      "1406078 executed!\n",
      "1409480 executed!\n",
      "1409512 executed!\n",
      "1386109 executed!\n",
      "1388213 executed!\n",
      "1409479 executed!\n",
      "1409511 executed!\n",
      "1386107 executed!\n",
      "1386108 executed!\n",
      "1387603 executed!\n",
      "1409478 executed!\n",
      "1409510 executed!\n",
      "1412535 executed!\n",
      "1412533 executed!\n",
      "1412534 executed!\n",
      "1386105 executed!\n",
      "1386106 executed!\n",
      "1388212 executed!\n",
      "1398260 executed!\n",
      "1412531 executed!\n",
      "1412532 executed!\n",
      "1386104 executed!\n",
      "1409476 executed!\n",
      "1409508 executed!\n",
      "1412530 executed!\n",
      "1373583 executed!\n",
      "1386103 executed!\n",
      "1387602 executed!\n",
      "1406077 executed!\n",
      "1409475 executed!\n",
      "1409507 executed!\n",
      "1386102 executed!\n",
      "1388211 executed!\n",
      "1398259 executed!\n",
      "1373582 executed!\n",
      "1386101 executed!\n",
      "1387601 executed!\n",
      "1409474 executed!\n",
      "1409506 executed!\n",
      "1388201 executed!\n",
      "1387600 executed!\n",
      "1408102 executed!\n",
      "1408108 executed!\n",
      "1411276 executed!\n",
      "1373581 executed!\n",
      "1398258 executed!\n",
      "1411273 executed!\n",
      "1411274 executed!\n",
      "1388200 executed!\n",
      "1408107 executed!\n",
      "1373580 executed!\n",
      "1375842 executed!\n",
      "1387599 executed!\n",
      "1406076 executed!\n",
      "1411271 executed!\n",
      "1411272 executed!\n",
      "1386100 executed!\n",
      "1408106 executed!\n",
      "1411269 executed!\n",
      "1411270 executed!\n",
      "1373579 executed!\n",
      "1386099 executed!\n",
      "1387598 executed!\n",
      "1388199 executed!\n",
      "1411267 executed!\n",
      "1411268 executed!\n",
      "1386098 executed!\n",
      "1411265 executed!\n",
      "1411266 executed!\n",
      "1386097 executed!\n",
      "1406075 executed!\n",
      "1408105 executed!\n",
      "1411263 executed!\n",
      "1411264 executed!\n",
      "1373578 executed!\n",
      "1388198 executed!\n",
      "1406074 executed!\n",
      "1408104 executed!\n",
      "1411261 executed!\n",
      "1411262 executed!\n",
      "1386095 executed!\n",
      "1398256 executed!\n",
      "1386094 executed!\n",
      "1408103 executed!\n",
      "1373577 executed!\n",
      "1395704 executed!\n",
      "1398255 executed!\n",
      "1406073 executed!\n",
      "1388197 executed!\n",
      "1373576 executed!\n",
      "1388196 executed!\n",
      "1389395 executed!\n",
      "1398254 executed!\n",
      "1387228 executed!\n",
      "1389394 executed!\n",
      "1407107 executed!\n",
      "1407108 executed!\n",
      "1407109 executed!\n",
      "1407104 executed!\n",
      "1407105 executed!\n",
      "1407106 executed!\n",
      "1409206 executed!\n",
      "1389393 executed!\n",
      "1391785 executed!\n",
      "1391786 executed!\n",
      "1391787 executed!\n",
      "1395703 executed!\n",
      "1407103 executed!\n",
      "1409205 executed!\n"
     ]
    }
   ],
   "source": [
    "print(len(ids), \" files present\")\n",
    "#for file in ids[-40:]:\n",
    "\n",
    "for file in ids:\n",
    "    with zip_file.open(file+filetype) as jsonfile:\n",
    "        data = json.load(jsonfile)\n",
    "        # -----------------------------\n",
    "        # DataFrame to store - Metadata\n",
    "        df_meta = pd.concat([df_meta, pd.DataFrame([data[\"meta\"]]).assign(filename=file, filetype=filetype)])\n",
    "        \n",
    "        # ----------------------------------\n",
    "        # DataFrame to store - match details\n",
    "        df_info = pd.DataFrame([data[\"info\"]])\n",
    "        df_match_temp = pd.concat([\n",
    "            pd.json_normalize(df_info['event'], sep='_').add_prefix('event_'),\n",
    "            pd.DataFrame(df_info[list(set(['balls_per_over','season', 'gender', 'city', 'venue', 'match_type', 'match_type_number', 'overs', 'team_type']) & set(df_info.columns))]),\n",
    "            df_info['dates'].apply(lambda x: [x[0], x[-1]]).apply(pd.Series).rename(columns={0: 'start_date', 1: 'end_date'}),\n",
    "            df_info['teams'].apply(lambda x: [x[0], x[1]]).apply(pd.Series).rename(columns={0: 'team_host', 1: 'team_visitor'}),\n",
    "            pd.json_normalize(df_info['toss'], sep='_').add_prefix('toss_'),\n",
    "            pd.json_normalize(df_info['outcome'], sep='_').add_prefix('outcome_')\n",
    "        ], axis=1).assign(match_id = file)\n",
    "        if 'player_of_match' in df_info.columns:\n",
    "            df_match_temp['player_of_match'] = df_info['player_of_match'].apply(lambda x: ','.join(x))\n",
    "            \n",
    "        df_match = pd.concat([df_match, df_match_temp])\n",
    "        \n",
    "        # -----------------------------------\n",
    "        # DataFrame to store official details\n",
    "        df_umpire = pd.json_normalize(df_info['officials'], sep = '_')\n",
    "        umpire_set = set()\n",
    "        \n",
    "        for column in df_umpire.columns:\n",
    "            umpire_set.update(df_umpire[column].explode().dropna())\n",
    "\n",
    "        df_umpire2 = pd.DataFrame(index=list(umpire_set), columns=df_umpire.columns).fillna(False)\n",
    "        \n",
    "        for column in df_umpire.columns:\n",
    "            df_umpire2[column] = df_umpire2.index.isin(df_umpire[column].explode().dropna())\n",
    "            \n",
    "        df_umpire2 = df_umpire2.reset_index().rename(columns={'index': 'name'}).assign(match_id = file)     \n",
    "        df_official = pd.concat([df_official, df_umpire2])\n",
    "\n",
    "        # -------------------------------------\n",
    "        # DataFrame to store - registry details\n",
    "        df_registry = pd.concat([\n",
    "            df_registry,\n",
    "            pd.DataFrame(list(data[\"info\"][\"registry\"][\"people\"].items()), columns=['people', 'identifier']).assign(match_id = file)\n",
    "        ])\n",
    "        \n",
    "        # -----------------------------------------\n",
    "        # DataFrame to store - match player details\n",
    "        df_player = pd.concat([\n",
    "            df_player,\n",
    "            pd.json_normalize(df_info['players']).melt(var_name='team', value_name='player').explode('player').assign(match_id = file)\n",
    "        ])\n",
    "        \n",
    "        # -------------------------------------------------\n",
    "        # DataFrame to store - innings details\n",
    "        df_innings = pd.concat([df_innings,\n",
    "                                pd.json_normalize(data['innings'], sep = '_').drop('overs', axis = 1).assign(match_id = file)])\n",
    "        \n",
    "        # -------------------------------------------------\n",
    "        # DataFrame to store - deliveries ball by ball\n",
    "        for i in data['innings']:\n",
    "            index = data['innings'].index(i)\n",
    "            df_deliveries = pd.concat([df_deliveries,\n",
    "                                        pd.json_normalize(i,\n",
    "                                                          record_path=['overs', 'deliveries'],\n",
    "                                                          meta=['team', ['overs', 'over']],\n",
    "                                                          sep='_'\n",
    "                                                         )\n",
    "                                        .assign(match_id=file, inning = index+1)\n",
    "                                       ])\n",
    "        \n",
    "        # --------------------------------------\n",
    "        # DataFrame to store - powerplay details\n",
    "        for i in data['innings']:\n",
    "            if 'powerplays' in pd.json_normalize(i).columns:\n",
    "                index = data['innings'].index(i)\n",
    "                df_powerplay = pd.concat([df_powerplay, pd.json_normalize(data['innings'][index], record_path = ['powerplays'], meta = ['team'], sep = '_').assign(match_id = file)])\n",
    "\n",
    "            if 'absent_hurt' in pd.json_normalize(i).columns:\n",
    "                index = data['innings'].index(i)\n",
    "                df_absent_hurt = pd.concat([\n",
    "                    df_absent_hurt,\n",
    "                    pd.json_normalize(data['innings'][index])[['team','absent_hurt']].explode('absent_hurt').assign(match_id = file)\n",
    "                ])                \n",
    "\n",
    "        df_miscounted_overs = pd.concat([df_miscounted_overs,pd.DataFrame([\n",
    "            {\n",
    "                \"team\": inning.get(\"team\", \"\"),\n",
    "                \"miscounted_over\": over_number,\n",
    "                \"balls\": over_data.get(\"balls\", \"\"),\n",
    "                \"umpire\": over_data.get(\"umpire\", \"\")\n",
    "            }\n",
    "            for inning in data.get(\"innings\", [])\n",
    "            for over_number, over_data in inning.get(\"miscounted_overs\", {}).items()\n",
    "        ]).assign(match_id = file)])\n",
    "        \n",
    "    print(file + \" executed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1082a5a",
   "metadata": {},
   "source": [
    "## Adding/Modifying additional fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7704b307",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T10:16:01.759595Z",
     "start_time": "2024-01-01T10:16:01.695544Z"
    }
   },
   "outputs": [],
   "source": [
    "match_id_list = \", \".join([f\"'{match_id}'\" for match_id in ids])\n",
    "\n",
    "df_meta['created'] = pd.to_datetime(df_meta['created'])\n",
    "\n",
    "# Merging registry details into match-player details\n",
    "df_player.reset_index(inplace = True, drop = True)\n",
    "df_registry.reset_index(inplace = True, drop = True)\n",
    "df_player.rename(columns = {'player':'name'}, inplace = True)\n",
    "df_player['player_id'] = df_player.merge(df_registry, how='left', left_on=['match_id', 'name'], right_on=['match_id', 'people'])['identifier']\n",
    "\n",
    "df_official.reset_index(inplace = True, drop = True)\n",
    "df_official['official_id'] = df_official.merge(df_registry, how='left', left_on=['match_id','name'], right_on=['match_id','people'])['identifier']\n",
    "\n",
    "df_miscounted_overs.reset_index(inplace = True, drop = True)\n",
    "\n",
    "df_innings.drop(['powerplays','absent_hurt'], axis=1, inplace=True, errors='ignore')\n",
    "df_innings.drop(df_innings.filter(like='miscounted_overs_').columns, axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "if not df_absent_hurt.empty:\n",
    "    df_absent_hurt.reset_index(inplace = True, drop = True)\n",
    "    df_absent_hurt.rename(columns = {'absent_hurt':'name'}, inplace = True)\n",
    "    df_absent_hurt['player_id'] = df_absent_hurt.merge(df_registry, how='left', left_on=['match_id', 'name'], right_on=['match_id', 'people'])['identifier']\n",
    "    \n",
    "df_deliveries.reset_index(inplace = True, drop = True)\n",
    "df_deliveries.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2548c616",
   "metadata": {},
   "source": [
    "## Load data into Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5569cd",
   "metadata": {},
   "source": [
    "#### 1. Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8906782",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T10:16:03.000795Z",
     "start_time": "2024-01-01T10:16:01.765653Z"
    }
   },
   "outputs": [],
   "source": [
    "# Upsert MetaData information\n",
    "query = psql.upsert(\n",
    "    engine,\n",
    "    dataFrame = df_meta,\n",
    "    table = \"meta\",\n",
    "    schema = \"dwh\",\n",
    "    pk_col = list(df_meta.columns),\n",
    "    update_col = list(df_meta.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b9bf05",
   "metadata": {},
   "source": [
    "#### 2. Officials(umpires)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61d86674",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T10:16:03.808640Z",
     "start_time": "2024-01-01T10:16:03.005866Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load official(umpires) information\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(f\"DELETE FROM dwh.official WHERE match_id IN ({match_id_list})\")\n",
    "    \n",
    "count_rows = df_official.to_sql('official', schema='dwh', con=engine, if_exists='append', method='multi', index=False)\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(\"\"\"\n",
    "        UPDATE dwh.official OF\n",
    "        SET is_registered = FALSE\n",
    "        FROM dwh.people P\n",
    "        WHERE OF.name = P.identifier AND P.identifier IS NULL;\n",
    "    \"\"\")\n",
    "    \n",
    "    conn.execute(\"\"\"\n",
    "        UPDATE dwh.official off\n",
    "        SET official_id_num = p.id\n",
    "        FROM dwh.people p\n",
    "        WHERE off.official_id = p.identifier\n",
    "        AND official_id_num IS NULL;\n",
    "    \"\"\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a38d81",
   "metadata": {},
   "source": [
    "#### 3. Player-match (players who played a particular match) & Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "112c2bc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T10:16:05.023299Z",
     "start_time": "2024-01-01T10:16:03.815450Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load match_player information into Stage table\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(\"TRUNCATE TABLE stg.match_player\")\n",
    "\n",
    "count_rows = df_player.to_sql('match_player', schema = 'stg', con = engine, if_exists='append', method = 'multi', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "419810c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T10:16:05.130309Z",
     "start_time": "2024-01-01T10:16:05.026035Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load match information into dwh layer\n",
    "with engine.connect() as conn:\n",
    "    conn.execution_options(isolation_level = \"AUTOCOMMIT\")\n",
    "    with conn.begin():\n",
    "        conn.execute(\"CALL dwh.LoadMatchPlayerAndTeam()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1907f590",
   "metadata": {},
   "source": [
    "#### 4. Match details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d3d2fb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T10:16:05.965776Z",
     "start_time": "2024-01-01T10:16:05.135646Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load match information into Stage table\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(\"TRUNCATE TABLE stg.match\")\n",
    "\n",
    "count_rows = df_match.to_sql('match', schema = 'stg', con = engine, if_exists='append', method = 'multi', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66c5ed1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T10:16:06.057354Z",
     "start_time": "2024-01-01T10:16:05.966793Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load match information into dwh layer\n",
    "with engine.connect() as conn:\n",
    "    conn.execution_options(isolation_level = \"AUTOCOMMIT\")\n",
    "    with conn.begin():\n",
    "        conn.execute(\"CALL dwh.LoadMatch()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a5225c",
   "metadata": {},
   "source": [
    "#### 5. absent hurt details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa7eded2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T10:16:06.570094Z",
     "start_time": "2024-01-01T10:16:06.065396Z"
    }
   },
   "outputs": [],
   "source": [
    "query = psql.insert_without_duplicate(\n",
    "    engine,\n",
    "    dataFrame = df_absent_hurt,\n",
    "    table = \"absent_hurt\",\n",
    "    schema = \"dwh\",\n",
    "    conflict_col = list(df_absent_hurt.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b190a5ee",
   "metadata": {},
   "source": [
    "#### 6. miscounted overs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "019b5937",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T10:16:07.138772Z",
     "start_time": "2024-01-01T10:16:06.579215Z"
    }
   },
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    conn.execute(f\"DELETE FROM dwh.miscounted_over WHERE match_id IN ({match_id_list})\")\n",
    "    \n",
    "count_rows = df_miscounted_overs.to_sql('miscounted_over', schema='dwh', con=engine, if_exists='append', method='multi', index=False)\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(\"\"\"\n",
    "        UPDATE dwh.miscounted_over MO\n",
    "        SET umpire = NULL\n",
    "        WHERE umpire = ''\n",
    "    \"\"\")\n",
    "    \n",
    "    conn.execute(\"\"\"\n",
    "        UPDATE dwh.miscounted_over MO\n",
    "        SET umpire_id_num = official_id_num\n",
    "        FROM dwh.official OFF\n",
    "        WHERE MO.match_id = OFF.match_id AND MO.umpire = OFF.name AND MO.umpire_id_num IS NULL;\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90291d99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T16:08:10.084299Z",
     "start_time": "2023-12-03T16:08:10.034595Z"
    }
   },
   "source": [
    "#### 7. innings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ecaacffd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T10:16:07.573658Z",
     "start_time": "2024-01-01T10:16:07.145485Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with engine.connect() as conn:\n",
    "    conn.execute(\"TRUNCATE TABLE stg.inning\")\n",
    "    \n",
    "df_innings.to_sql('inning', schema = 'stg', con = engine, if_exists='append', method = 'multi', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e5fec3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T10:16:07.680917Z",
     "start_time": "2024-01-01T10:16:07.575663Z"
    }
   },
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    conn.execution_options(isolation_level = \"AUTOCOMMIT\")\n",
    "    with conn.begin():\n",
    "        conn.execute(\"CALL dwh.LoadInning()\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb0563a",
   "metadata": {},
   "source": [
    "#### 8. powerplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0aca76d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T10:16:08.111008Z",
     "start_time": "2024-01-01T10:16:07.687989Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with engine.connect() as conn:\n",
    "    conn.execute(\"TRUNCATE TABLE stg.powerplay\")\n",
    "\n",
    "df_powerplay.to_sql('powerplay', schema = 'stg', con = engine, if_exists='append', method = 'multi', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a0be5aef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T10:16:08.219394Z",
     "start_time": "2024-01-01T10:16:08.111008Z"
    }
   },
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    conn.execution_options(isolation_level = \"AUTOCOMMIT\")\n",
    "    with conn.begin():\n",
    "        conn.execute(\"CALL dwh.LoadPowerplay()\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed483dd0",
   "metadata": {},
   "source": [
    "#### 9. delivery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "963eb83d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T10:57:26.131501Z",
     "start_time": "2023-12-30T10:56:27.784827Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41580"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with engine.connect() as conn:\n",
    "    conn.execute(\"TRUNCATE TABLE stg.delivery\")\n",
    "\n",
    "df_deliveries.to_sql('delivery', \n",
    "                     schema = 'stg', \n",
    "                     con = engine, \n",
    "                     if_exists='append', \n",
    "                     method = 'multi', \n",
    "                     dtype = {\n",
    "                                 \"wickets\":altypes.JSON(none_as_null=True),\n",
    "                                 \"replacements_match\":altypes.JSON(none_as_null=True),\n",
    "                                 \"replacements_role\":altypes.JSON(none_as_null=True)\n",
    "                             },\n",
    "                     index = False,\n",
    "                     chunksize = 5000)\n",
    "\n",
    "## 692 records per second | chunksize = 10k\n",
    "# 1076 records per second | chunksize = 2k\n",
    "# 1050 records per second | chunksize = 1024\n",
    "# 1015 records per second | chunksize = 1k\n",
    "# 1005 records per second | chunksize = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30e53f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    conn.execution_options(isolation_level = \"AUTOCOMMIT\")\n",
    "    with conn.begin():\n",
    "        conn.execute(\"CALL dwh.LoadDelivery()\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "156.042px",
    "left": "1382.44px",
    "right": "20px",
    "top": "120px",
    "width": "315.417px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
