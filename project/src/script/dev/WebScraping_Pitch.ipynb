{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37e6af0b",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0443170",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T09:10:53.394690Z",
     "start_time": "2023-12-09T09:10:53.369119Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import espncricinfo as ci\n",
    "import ipywidgets as widgets\n",
    "import os\n",
    "import chromedriver_autoinstaller\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bf4a85",
   "metadata": {},
   "source": [
    "# Setting configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb6fe500",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T09:10:54.716379Z",
     "start_time": "2023-12-09T09:10:53.958788Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ShyamRangapure\\\\anaconda3\\\\Lib\\\\site-packages\\\\chromedriver_autoinstaller\\\\121\\\\chromedriver.exe'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "comm_filepath = os.path.abspath(os.path.join(os.getcwd(), \"../../../data/CommExtract/\"))\n",
    "chromedriver_autoinstaller.install() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae02b101",
   "metadata": {},
   "source": [
    "# Initializing paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf4e7f9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T09:10:54.732683Z",
     "start_time": "2023-12-09T09:10:54.724490Z"
    }
   },
   "outputs": [],
   "source": [
    "year = '2023'\n",
    "series = 'indian-premier-league-2023'\n",
    "matchid = '66173'\n",
    "scroll_pause_time = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa75d02",
   "metadata": {},
   "source": [
    "# Web Scrapping - Cricbuzz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf5bb96",
   "metadata": {},
   "source": [
    "### Finding all the series from the yearly calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ee3000d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T09:10:56.180488Z",
     "start_time": "2023-12-09T09:10:55.696296Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209 series found in the year 2023\n",
      "Current series selected is :- indian-premier-league-2023\n",
      "Series ID : 5945\n"
     ]
    }
   ],
   "source": [
    "base_url = 'https://www.cricbuzz.com/cricket-scorecard-archives/'\n",
    "url = base_url + year\n",
    "\n",
    "\n",
    "page = requests.get(url)\n",
    "bs = BeautifulSoup(page.content, 'lxml')\n",
    "\n",
    "links = bs.find_all('a', href=lambda href: href and 'matches' in href)\n",
    "\n",
    "series_list = []\n",
    "for link in links:\n",
    "    href = link['href']\n",
    "    columns = href.split('/')[2:4]\n",
    "    #columns[-1] = columns[-1].replace('-', ' ') ---> for better readability convert code to proper text\n",
    "    series_list.append(columns)\n",
    "\n",
    "series_id = next((row[0] for row in series_list if row[1] == series), None)\n",
    "\n",
    "print(str(len(series_list)) + ' series found in the year ' + year)\n",
    "print('Current series selected is :- ' + series)\n",
    "print('Series ID : ' + series_id)\n",
    "#series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433d3a0d",
   "metadata": {},
   "source": [
    "### Finding all the matches from the given series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec81d51d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T09:10:57.175018Z",
     "start_time": "2023-12-09T09:10:56.525969Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 matches found in the series - indian premier league 2023 for the year 2023\n",
      "Current match selected is :- pbks-vs-kkr-2nd-match-indian-premier-league-2023\n",
      "Match ID : 66173\n"
     ]
    }
   ],
   "source": [
    "base_url = 'https://www.cricbuzz.com/cricket-series/'\n",
    "url = base_url + series_id + '/' + series + '/matches'\n",
    "\n",
    "page = requests.get(url)\n",
    "bs = BeautifulSoup(page.content, 'lxml')\n",
    "\n",
    "links = bs.select('div.page')[0].find_all('a', href=lambda href: href and (\n",
    "    '/cricket-scores/' in href or (series in href and '/live-cricket-scores/' in href)))\n",
    "\n",
    "matches = []\n",
    "for link in links:\n",
    "    href = link['href']\n",
    "    column = href.split('/')[2:4]\n",
    "    matches.append(column)\n",
    "    \n",
    "matches = list(set(map(tuple,matches)))\n",
    "matches.sort(key=lambda x: int(x[0]))\n",
    "\n",
    "# match_id = next((row[0] for row in matches if row[1] == match_wg.value), None)\n",
    "# match_id = MATCHID\n",
    "match = next((row[1] for row in matches if row[0] == matchid), None)\n",
    "\n",
    "print(str(len(matches)) + ' matches found in the series - ' + series.replace('-', ' ') + ' for the year ' + year)\n",
    "print('Current match selected is :- ' + match)\n",
    "print('Match ID : ' + matchid)\n",
    "\n",
    "#matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bfd67c",
   "metadata": {},
   "source": [
    "### Get full commentary using a dynamic scroll with a timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "767d9c16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T09:13:08.917293Z",
     "start_time": "2023-12-09T09:12:06.601309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_height - 4125\n",
      "new_height - 5495\n",
      "New content found. Resetting start_time...\n",
      "new_height - 5495\n",
      "new_height - 5495\n",
      "new_height - 5495\n",
      "new_height - 5495\n",
      "new_height - 5495\n",
      "new_height - 5495\n",
      "new_height - 6947\n",
      "New content found. Resetting start_time...\n",
      "new_height - 7009\n",
      "New content found. Resetting start_time...\n",
      "new_height - 7009\n",
      "new_height - 7009\n",
      "new_height - 7009\n",
      "new_height - 7009\n",
      "new_height - 7009\n",
      "new_height - 8742\n",
      "New content found. Resetting start_time...\n",
      "new_height - 8742\n",
      "new_height - 8742\n",
      "new_height - 8742\n",
      "new_height - 8742\n",
      "new_height - 8742\n",
      "new_height - 10473\n",
      "New content found. Resetting start_time...\n",
      "new_height - 10473\n",
      "new_height - 10473\n",
      "new_height - 10473\n",
      "new_height - 10473\n",
      "new_height - 10473\n",
      "new_height - 12517\n",
      "New content found. Resetting start_time...\n",
      "new_height - 12517\n",
      "new_height - 12517\n",
      "new_height - 12517\n",
      "new_height - 12517\n",
      "new_height - 12517\n",
      "new_height - 14047\n",
      "New content found. Resetting start_time...\n",
      "new_height - 14140\n",
      "New content found. Resetting start_time...\n",
      "new_height - 14140\n",
      "new_height - 14140\n",
      "new_height - 14140\n",
      "new_height - 14140\n",
      "new_height - 15162\n",
      "New content found. Resetting start_time...\n",
      "new_height - 15193\n",
      "New content found. Resetting start_time...\n",
      "new_height - 15193\n",
      "new_height - 15193\n",
      "new_height - 15193\n",
      "new_height - 15193\n",
      "new_height - 17440\n",
      "New content found. Resetting start_time...\n",
      "new_height - 17440\n",
      "new_height - 17440\n",
      "new_height - 17440\n",
      "new_height - 17440\n",
      "new_height - 17440\n",
      "new_height - 18989\n",
      "New content found. Resetting start_time...\n",
      "new_height - 19020\n",
      "New content found. Resetting start_time...\n",
      "new_height - 19020\n",
      "new_height - 19020\n",
      "new_height - 19020\n",
      "new_height - 19020\n",
      "new_height - 19020\n",
      "new_height - 21016\n",
      "New content found. Resetting start_time...\n",
      "new_height - 21016\n",
      "new_height - 21016\n",
      "new_height - 21016\n",
      "new_height - 21016\n",
      "new_height - 21016\n",
      "new_height - 22648\n",
      "New content found. Resetting start_time...\n",
      "new_height - 22648\n",
      "new_height - 22648\n",
      "new_height - 22648\n",
      "new_height - 22648\n",
      "new_height - 22648\n",
      "new_height - 22648\n",
      "new_height - 24722\n",
      "New content found. Resetting start_time...\n",
      "new_height - 24722\n",
      "new_height - 24722\n",
      "new_height - 24722\n",
      "new_height - 24722\n",
      "new_height - 26246\n",
      "New content found. Resetting start_time...\n",
      "new_height - 26308\n",
      "New content found. Resetting start_time...\n",
      "new_height - 26308\n",
      "new_height - 26308\n",
      "new_height - 26308\n",
      "new_height - 26308\n",
      "new_height - 28618\n",
      "New content found. Resetting start_time...\n",
      "new_height - 28618\n",
      "new_height - 28618\n",
      "new_height - 28618\n",
      "new_height - 28618\n",
      "new_height - 30344\n",
      "New content found. Resetting start_time...\n",
      "new_height - 30344\n",
      "new_height - 30344\n",
      "new_height - 30344\n",
      "new_height - 31841\n",
      "New content found. Resetting start_time...\n",
      "new_height - 31872\n",
      "New content found. Resetting start_time...\n",
      "new_height - 31872\n",
      "new_height - 31872\n",
      "new_height - 31872\n",
      "new_height - 35007\n",
      "New content found. Resetting start_time...\n",
      "new_height - 35007\n",
      "new_height - 35007\n",
      "new_height - 35007\n",
      "new_height - 35007\n",
      "new_height - 34949\n",
      "New content found. Resetting start_time...\n",
      "new_height - 34949\n",
      "new_height - 34949\n",
      "new_height - 34949\n",
      "new_height - 34949\n",
      "new_height - 34949\n",
      "new_height - 34949\n",
      "new_height - 34949\n",
      "new_height - 34949\n",
      "new_height - 34949\n",
      "new_height - 34949\n",
      "new_height - 34949\n",
      "new_height - 34949\n",
      "new_height - 34949\n",
      "new_height - 34949\n",
      "new_height - 34949\n",
      "new_height - 34949\n",
      "new_height - 34949\n",
      "new_height - 34949\n",
      "new_height - 34949\n",
      "new_height - 34949\n",
      "new_height - 34949\n",
      "new_height - 34949\n",
      "No new content found. Breaking now...\n"
     ]
    }
   ],
   "source": [
    "base_url = 'https://www.cricbuzz.com/cricket-scores/'\n",
    "url = base_url + matchid + '/' + match\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "#chrome_options.add_argument(\"--headless\")\n",
    "\n",
    "driver = webdriver.Chrome(options=chrome_options)   # Set up the driver\n",
    "driver.get(url)\n",
    "\n",
    "wait = WebDriverWait(driver, 10)   # Set a wait time for explicit waits\n",
    "\n",
    "# Find the element by text\n",
    "element_text = \"Load More Commentary\"\n",
    "element_xpath = f\"//*[contains(text(), '{element_text}')]\"\n",
    "element = wait.until(EC.visibility_of_element_located((By.XPATH, element_xpath)))\n",
    "\n",
    "driver.execute_script(\"arguments[0].scrollIntoView();\", element)   # Scroll to the element\n",
    "\n",
    "driver.execute_script(\"arguments[0].click();\", element)   # Perform JavaScript click\n",
    "\n",
    "# Get scroll height\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "print(\"last_height - \" + str(last_height))\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "while True:\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")   # Scroll down to bottom\n",
    "    time.sleep(0.3)   # Wait to load page\n",
    "    #driver.implicitly_wait(0.3)\n",
    "    #element = wait.until(EC.presence_of_element_located((By.XPATH, element_xpath)))\n",
    "\n",
    "\n",
    "    # Calculate new scroll height and compare with last scroll height\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    print(\"new_height - \" + str(new_height))\n",
    "    \n",
    "    if new_height != last_height:\n",
    "        start_time = time.time()\n",
    "        print(\"New content found. Resetting start_time...\")\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    if elapsed_time > scroll_pause_time:\n",
    "        print(\"No new content found. Breaking now...\")\n",
    "        break\n",
    "    \n",
    "    last_height = new_height\n",
    "\n",
    "# Get the updated page source\n",
    "updated_page_source = driver.page_source\n",
    "\n",
    "# Perform further actions on the updated page source if needed\n",
    "bs = BeautifulSoup(updated_page_source, 'lxml')\n",
    "#print(bs.body.prettify())\n",
    "\n",
    "driver.quit()   # Close the driver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1213bf45",
   "metadata": {},
   "source": [
    "# Extract clean text parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e56e0c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-14T19:48:25.594531Z",
     "start_time": "2023-09-14T19:48:25.527443Z"
    }
   },
   "outputs": [],
   "source": [
    "div_elements = bs.find_all('div', {'ng-include': \"'commentary'\"})\n",
    "\n",
    "text_parts = []\n",
    "for div in div_elements:\n",
    "    texts = div.find_all(text=True)\n",
    "    cleaned_texts = [text.strip() for text in texts if text.strip() and \n",
    "                     not text.strip().startswith('ngIf:') and \n",
    "                     not text.strip().startswith('end ngIf:') and \n",
    "                     not text.strip().startswith('ngRepeat:') and\n",
    "                     not text.strip().startswith('ngInclude:') and\n",
    "                     not text.strip().startswith('end ngRepeat')]\n",
    "    text_parts.extend(cleaned_texts)\n",
    "\n",
    "#print(text_parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153b963a",
   "metadata": {},
   "source": [
    "# Save the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf7d602",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-14T19:48:36.659986Z",
     "start_time": "2023-09-14T19:48:36.636403Z"
    }
   },
   "outputs": [],
   "source": [
    "path = comm_filepath + '\\\\comm_' + matchid + '.txt'\n",
    "\n",
    "# Delete the file if exists\n",
    "os.remove(path) if os.path.exists(path) else None\n",
    "\n",
    "# Save the list to a text file\n",
    "with open(path, 'w') as f:\n",
    "    for item in text_parts:\n",
    "        f.write(f\"{item}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
